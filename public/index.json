[{"content":"Introduction For anyone diving into DevOps, there\u0026rsquo;s a moment when the theory of Kubernetes—all the talk of Pods, Services, and Deployments—needs to meet the messy reality of practice. My journey with the \u0026ldquo;Log-Pong\u0026rdquo; application was exactly that: a hands-on, often challenging, but ultimately rewarding experience that took me from manually managing resources to orchestrating a fully automated GitOps pipeline.\nThis post isn\u0026rsquo;t just a project showcase. It\u0026rsquo;s a story about the power of starting with the fundamentals, embracing the \u0026ldquo;manual\u0026rdquo; way to build deep understanding, and then leveraging that knowledge to build a professional, automated workflow. If you\u0026rsquo;re on a similar path, I hope my story resonates and offers some useful insights.\nThe Log-Pong Application Before we dive into the how (the deployment), let\u0026rsquo;s quickly cover the what. The \u0026ldquo;Log-Pong\u0026rdquo; stack consists of two simple microservices designed to demonstrate key Kubernetes concepts:\nThe pingpong-app (The Backend):\nWhat it is: A stateful backend service. Technology: Node.js with the Koa framework, connected to a PostgreSQL database. What it does: Its only job is to expose an API endpoint (/ping). When called, it increments a counter in the database and returns the new number of \u0026ldquo;pongs.\u0026rdquo; This service represents a stateful component whose data must persist. The log-output-app (The Frontend/Aggregator):\nWhat it is: A frontend service that gathers information from various sources. Technology: Node.js with Koa, running in a unique two-container Pod. What it does: A writer container continuously writes the current timestamp to a shared file. A reader container waits for requests. When a request comes in, it reads the timestamp from the shared file, fetches a message from a Kubernetes ConfigMap, and makes an HTTP call to the pingpong-app to get the current pong count. It then combines all this information into a single string. How They Work Together: The user interacts with the log-output-app, which in turn communicates with the pingpong-app over the cluster\u0026rsquo;s internal network. The final output looks something like this:\nfile content: this text is from file env variable: MESSAGE=hello world 2025-07-21T10:30:00.123Z: a1b2c3d4e5f6... Ping / Pongs: 42 It\u0026rsquo;s a simple system, but its architecture is perfect for exploring the core concepts of Kubernetes networking, state management, and configuration. Now, let\u0026rsquo;s get into how it was deployed.\nManual Deployment Every project starts somewhere. Mine began with the two applications described above. Initially, getting them to run was a manual process of building Docker images and applying Kubernetes manifests one by one.\n# 1. Build the image docker build -t my-username/pingpong-app . # 2. Push it to a registry docker push my-username/pingpong-app # 3. Deploy it to the cluster kubectl apply -f manifests/deployment.yaml kubectl apply -f manifests/service.yaml I had to do this for both applications. It was tedious, but it was also the perfect way to learn the fundamentals. I wasn\u0026rsquo;t just running a script; I was forced to understand what each kubectl apply command was actually doing. What\u0026rsquo;s a Deployment? Why does it need a Service? How do labels and selectors work? This manual phase was my classroom.\nService Connectivity Running the apps was one thing; making them talk to each other was a whole new challenge. This is where the real learning began.\nMy first attempt involved the shared volume between the \u0026ldquo;writer\u0026rdquo; and \u0026ldquo;reader\u0026rdquo; containers, but the real breakthrough came when I truly understood Kubernetes Services. By giving my pingpong deployment a ClusterIP service, it received a stable DNS name inside the cluster.\nSuddenly, my log-output app could reliably find and talk to it over the network.\n// In the log-output reader\u0026#39;s code const PINGPONG_URL = \u0026#39;http://pingpong-svc:3001/ping\u0026#39;; // ... const pingResponse = await axios.get(PINGPONG_URL); const pingCount = pingResponse.data.pong; This was a huge \u0026ldquo;aha!\u0026rdquo; moment. I had moved from a shared-filesystem model to true service-to-service communication, the foundation of microservice architecture.\ngraph TD ExternalUser[External User] --\u0026gt; KubernetesIngress(Kubernetes Ingress\\n(e.g., /log-output)) KubernetesIngress --\u0026gt; ServiceLogOutput(Service: log-output\\n(Type: ClusterIP)) ServiceLogOutput --\u0026gt; PodLogOutput(Pod: log-output\\n\\n - Reader Container\\n - Writer Container) ServiceLogOutput --\u0026gt; ServicePingpong(Service: pingpong\\n(Type: ClusterIP)) PodLogOutput --\u0026gt; ServicePingpong ServicePingpong --\u0026gt; PodPingpong(Pod: pingpong\\n\\n - Koa App Container) It\u0026rsquo;s a simple system, but its architecture is perfect for exploring the core concepts of Kubernetes networking, state management, and configuration. Now, let\u0026rsquo;s get into how it was deployed.\nGitOps Automation The manual workflow had taught me a lot, but it was slow and error-prone. It was time to automate. I decided to refactor the entire project into a professional GitOps workflow using ArgoCD.\nThis meant a fundamental change in structure:\npingpong-code Repo: Contained only the application source code. log-output-code Repo: Contained only its application source code. log-pong-config Repo: Contained only the Kubernetes YAML manifests. This became my single source of truth. Next, I built a CI/CD pipeline with GitHub Actions for each application repository. On every push to main, the pipeline would:\nBuild a new Docker image and tag it with the commit SHA. Push the image to Docker Hub. Check out the log-pong-config repository. Automatically update the image: tag in the deployment manifest. Commit and push the change to the config repo. # A snippet from the GitHub Actions workflow - name: Update Image Tag run: | sed -i \u0026#39;s|image: .*|image: ${{ secrets.DOCKERHUB_USERNAME }}/pingpong-app:${{ github.sha }}|g\u0026#39; log-pong-config/manifests/rollout.yaml The final piece was ArgoCD. I pointed it at my log-pong-config repository. Now, whenever the CI pipeline pushed an updated image tag, ArgoCD would detect the change and automatically sync it with my cluster. My job was done. I had created a fully automated, end-to-end deployment pipeline.\nReliability Enhancements With the core workflow in place, I added two more features to make the system truly robust.\nReadiness Probes: The pingpong app is useless without its database. I configured a readinessProbe that hits a /healthz endpoint. This endpoint only returns a 200 OK if the database connection is active. Now, Kubernetes won\u0026rsquo;t send traffic to a pingpong pod until it\u0026rsquo;s confirmed it can do its job.\nTo prove this, I simulated a database failure by deleting its StatefulSet. When the pingpong pod tried to restart, it couldn\u0026rsquo;t connect. Running kubectl describe pod on the new pod revealed exactly what was happening in the events log:\nStatus: Running IP: 10.68.2.70 Ready: False ... Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 15s scheduler Successfully assigned default/pingpong-rollout... Normal Pulled 15s kubelet Container image \u0026#34;kylmps/pingpong:5\u0026#34; already present... Normal Created 15s kubelet Created container pingpong Normal Started 15s kubelet Started container pingpong Warning Unhealthy 4s kubelet Readiness probe failed: HTTP probe failed with statuscode: 500 The probe was working perfectly, preventing the broken pod from receiving traffic and protecting the system from cascading failures.\nCanary Deployments \u0026amp; Automated Analysis: To deploy updates safely, I switched from a Deployment to an Argo Rollouts Rollout resource. I configured it to perform canary releases and defined an AnalysisTemplate to monitor CPU usage. If a new version causes a CPU spike, the rollout is automatically aborted and rolled back. No human intervention required.\nConclusion: The Journey is the Destination Building the Log-Pong stack taught me more than any tutorial ever could. By starting manually, I was forced to learn the \u0026ldquo;why\u0026rdquo; behind every Kubernetes object. That fundamental knowledge was the bedrock upon which I could confidently build a complex, automated GitOps workflow.\nIf you\u0026rsquo;re just starting out, embrace the manual steps. Break things. Fix them. Understand the moving parts. Because when you finally automate, you\u0026rsquo;ll be doing it with the confidence of someone who knows exactly what\u0026rsquo;s happening under the hood.\n","permalink":"http://localhost:1313/blog/my-kubernetes-journey/","summary":"\u003ch3 id=\"introduction\"\u003eIntroduction\u003c/h3\u003e\n\u003cp\u003eFor anyone diving into DevOps, there\u0026rsquo;s a moment when the theory of Kubernetes—all the talk of Pods, Services, and Deployments—needs to meet the messy reality of practice. My journey with the \u0026ldquo;Log-Pong\u0026rdquo; application was exactly that: a hands-on, often challenging, but ultimately rewarding experience that took me from manually managing resources to orchestrating a fully automated GitOps pipeline.\u003c/p\u003e\n\u003cp\u003eThis post isn\u0026rsquo;t just a project showcase. It\u0026rsquo;s a story about the power of starting with the fundamentals, embracing the \u0026ldquo;manual\u0026rdquo; way to build deep understanding, and then leveraging that knowledge to build a professional, automated workflow. If you\u0026rsquo;re on a similar path, I hope my story resonates and offers some useful insights.\u003c/p\u003e","title":"Kubernetes Journey: From kubectl to GitOps"},{"content":"Introduction: The Project That Taught Me Everything In the world of DevOps, you can read documentation for months, but nothing solidifies your skills like building something real. For me, that \u0026ldquo;something\u0026rdquo; was a seemingly simple Todo application. This project, inspired by the practical challenges presented in devopswithkubernetes.com, became my personal deep dive into Kubernetes, taking me from the humble beginnings of kubectl apply on my local machine to orchestrating a state-of-the-art, multi-environment GitOps workflow on Google Kubernetes Engine (GKE).\nThis post is the story of that journey. It’s a chronicle of the real-world problems, the late-night debugging sessions, and the architectural \u0026ldquo;aha!\u0026rdquo; moments that are often left out of the tutorials. It’s proof that by embracing complexity and solving problems from the ground up, you can build not just an application, but a truly professional and resilient platform. This is how I went from knowing Kubernetes to understanding it.\nChapter 1: The Application Stack - A Tale of Three Microservices The project started with a simple goal: build a Todo app. To truly learn microservice architecture, I broke it down into three distinct services, each with its own responsibility:\nThe todo-backend: The heart of the operation. A Node.js API that handles all business logic, from creating tasks to marking them as done. It is the stateful component, connected to a PostgreSQL database. The todo-frontend: The face of the application. A Node.js server that renders the user interface, making calls to the backend to manage tasks. The broadcaster: The town crier. A decoupled notification service that listens for events (like \u0026ldquo;new todo created\u0026rdquo;) from the backend via a NATS message queue and forwards them to a Discord channel. This separation was my first major architectural decision, forcing me to think about how services discover and communicate with each other inside a Kubernetes cluster.\nChapter 2: The First Real-World Failure: The Unready Pod My first deployment to GKE was met with a classic, humbling problem: the todo-backend pod was stuck in a 0/1 READY state. The logs revealed the truth: FATAL: password authentication failed for user \u0026quot;todo_user\u0026quot;.\nThe \u0026ldquo;aha!\u0026rdquo; moment was realizing that the PostgreSQL StatefulSet wasn\u0026rsquo;t running its initialization script because its PersistentVolumeClaim (PVC) already contained data from a previous failed attempt. The database thought it was already set up. This taught me a critical lesson in managing stateful applications: you have to understand the lifecycle of your data. The only solution was to completely delete the PVC and the StatefulSet to force a truly clean start.\nChapter 3: Building a Declarative Foundation with Kustomize With the application running, it was time to professionalize the deployment process. I abandoned scattered kubectl apply commands and embraced a declarative approach using Kustomize. This was the cornerstone of the entire GitOps structure.\nI created a new, dedicated todo-config repository to act as the single source of truth for my cluster\u0026rsquo;s state. The structure is clean and powerful:\nbase/: Contains the generic, shared manifests for all services. overlays/: Contains environment-specific patches. This is where the magic happens. In overlays/staging, I patch the broadcaster to disable Discord notifications and remove the database backup CronJob. In overlays/production, I use a different patch to enable these features. This structure means my base configuration is clean and reusable, and the differences between my environments are explicitly and clearly defined in code.\nChapter 4: The CI/CD Pipeline - Automating Staging and Production With a declarative configuration in place, I built the automation engine with GitHub Actions. Each of the three microservice repositories received its own independent CI workflow. This pipeline perfectly follows the instructions I set for myself, enabling multiple branch-specific environments:\nDeploy to Staging: A git push to the main branch of any service kicks off the workflow. It builds a new image and updates the kustomization.yaml in the staging overlay of the todo-config repo. Deploy to Production: When I\u0026rsquo;m ready for a production release, I create a version tag (e.g., v1.2.0). The same workflow detects this and, instead of updating the staging overlay, it updates the production overlay. This is the GitOps dream in action. My cluster state is now a direct reflection of my Git history, and deployments are a matter of a simple git push or git tag.\nChapter 5: State-of-the-Art Monitoring with Prometheus and Grafana A running application is one thing; a healthy application is another. To achieve true production readiness, I built a robust monitoring stack using the industry-standard tools: Prometheus and Grafana.\nI deployed a production-ready NATS message queue using its official Helm chart, and with a simple configuration change, I enabled its Prometheus metrics endpoint.\n# values.yaml for the NATS Helm chart metrics: enabled: true serviceMonitor: enabled: true namespace: prometheus # The namespace where Prometheus is running This serviceMonitor object is the key. It tells Prometheus how to automatically discover and start scraping metrics from my NATS cluster. After port-forwarding to the Prometheus pod, I could instantly verify that data was flowing with a simple query\nWith metrics flowing, the final step was visualization. I port-forwarded to the Grafana service, imported a pre-built NATS dashboard, and was immediately greeted with a real-time overview of my entire messaging infrastructure: CPU and memory usage, message throughput, and active client connections. This isn\u0026rsquo;t just a pretty graph; it\u0026rsquo;s the command center for my application\u0026rsquo;s health.\nWith metrics flowing, the final step was visualization. I port-forwarded to the Grafana service, imported a pre-built NATS dashboard, and was immediately greeted with a real-time overview of my entire messaging infrastructure: CPU and memory usage, message throughput, and active client connections. This isn\u0026rsquo;t just a pretty graph; it\u0026rsquo;s the command center for my application\u0026rsquo;s health.\nChapter 6: Advanced Deployments - Canary Releases with Automatic Rollback Deploying directly to production is risky. To mitigate this, I implemented an advanced Canary release strategy using Argo Rollouts. This is where the power of the monitoring stack truly shines.\nInstead of a standard Kubernetes Deployment, I now use an Argo Rollout resource. This allows me to define a precise, automated release process:\nInitial Canary: When a new version is deployed to production, Argo Rollouts sends only 20% of live traffic to it. Automated Analysis: For the next minute, it pauses. During this time, an AnalysisTemplate I wrote continuously runs a Prometheus query to check the application\u0026rsquo;s CPU usage. The Safety Net: If the CPU usage for the new version remains below my defined threshold (result[0] \u0026lt;= 0.5), the rollout proceeds, gradually shifting more traffic to the new version. Automatic Malfunction Detection: If the CPU usage spikes, the AnalysisTemplate fails. Argo Rollouts immediately and automatically aborts the deployment and rolls back to the previous stable version. No human intervention is required. # A snippet from my AnalysisTemplate ... metrics: - name: cpu-usage-sum interval: 1m count: 5 provider: prometheus: address: http://prometheus-kube-prometheus-prometheus.prometheus.svc.cluster.local:9090 query: | sum(rate(container_cpu_usage_seconds_total{namespace=\u0026#39;{{args.namespace}}\u0026#39;, container!=\u0026#39;\u0026#39;}[5m])) successCondition: \u0026#34;result[0] \u0026lt;= 0.5\u0026#34; failureCondition: \u0026#34;result[0] \u0026gt; 0.5\u0026#34; This is the pinnacle of a modern CI/CD pipeline: not just automated deployment, but automated, metric-driven safety.\nChapter 7: Professional Touches - Routing and Secrets With the core application and deployment strategy in place, I tackled two final topics to elevate the project to a professional standard.\n1. Hostname-Based Routing with the Gateway API: Instead of messy path-based routing (/staging/todo), I implemented the industry-standard hostname-based routing. This keeps my application code clean and environment-agnostic.\nHow it Works: I used Kustomize overlays to patch my HTTPRoute manifest. The staging overlay sets the hostname to staging.34.36.101.217.nip.io, while the production overlay sets it to todo.34.36.101.217.nip.io. The nip.io service provides a free and seamless way to get wildcard DNS for any IP, allowing me to use professional routing patterns without configuring a real domain. 2. Secrets Management: The instructions allowed me to assume secrets were handled externally, but a professional engineer plans for reality. In a real system, you never commit plaintext secrets to Git.\nThe \u0026ldquo;Easy\u0026rdquo; Way (What I did for now): I manually created the secrets in the cluster using kubectl create secret. This works, but it\u0026rsquo;s not repeatable. The \u0026ldquo;Right\u0026rdquo; Way (The Next Step): The industry-standard solution is to use a tool like HashiCorp Vault or GCP Secret Manager combined with the External Secrets Operator. The operator would run in my cluster, read secret references from my Git repository, and securely fetch the actual secret values from the vault, creating the Kubernetes secrets just in time for my application to use them. This is the most secure and scalable approach. Chapter 8: Real-World Refinements - Confronting State As the platform stabilized, I took a step back to critically review my own work. A good engineer knows that the job isn\u0026rsquo;t just about making things work, but making them work correctly and efficiently. This review uncovered several important discrepancies—the kind of subtle but significant issues that separate a prototype from a production-grade system.\n1. The Stateful Frontend: A Lesson in ReadWriteOnce\nMy biggest \u0026ldquo;aha!\u0026rdquo; moment during the review was realizing I had made my frontend stateful, and understanding the implications.\nThe Goal: I wanted the random image on the frontend to be persistent. If a pod died, I didn\u0026rsquo;t want to wait for a new image to be downloaded. I correctly identified that this required a PersistentVolume. The Implementation: I attached a PersistentVolumeClaim to my todo-frontend Deployment. This worked perfectly for a single replica, and it was a fantastic hands-on lesson in how pods can claim and use persistent storage. The Hidden Flaw: However, this approach uses a ReadWriteOnce (RWO) volume. I learned this means the underlying storage can only be mounted by one pod at a time. It was a scaling time bomb. If I had scaled the frontend to two replicas, the second pod would have failed to start because the volume was already \u0026ldquo;locked\u0026rdquo; by the first. The \u0026ldquo;Right\u0026rdquo; Way for Shared State: To achieve my goal of sharing one volume across multiple replicas, I would need a ReadWriteMany (RWX) volume, likely backed by a network file system like Google Cloud Filestore. This is a more advanced solution, but it\u0026rsquo;s the correct pattern for shared, writable state. For now, I\u0026rsquo;m keeping the RWO volume as a concrete reminder of this crucial lesson, but I know the path forward for a truly scalable solution. 2. The Image Tag Mismatch Dance: When GitOps Gets Stuck\nEven with the correct Project ID, my pods were still failing to pull images, reporting NotFound for tags like staging-initial. This was a crucial lesson in the timing of GitOps.\nThe Problem: My base Kustomize configuration specified newTag: staging-initial for the images. Kubernetes tried to pull these images immediately. However, my CI/CD pipeline builds images with SHA-based tags (e.g., staging-b287111) and then updates the kustomization.yaml in the overlays/staging directory with these new, correct tags. The staging-initial image simply didn\u0026rsquo;t exist in my GCR. The Complexity: This creates a race condition. The initial deployment attempts to pull a non-existent image, causing pods to get stuck in ImagePullBackOff. Even when the CI/CD pipeline successfully updates the Git repository with the correct SHA-based tags, the existing, failing pods might not immediately pick up the new image reference or restart. They remain in a persistent retry loop for the old, non-existent image. The Solution (Next Step): To unblock the current deployment, I need to ensure that an image with the staging-initial tag exists in my GCR for each service. Alternatively, I can force a rollout of the deployments to make them pick up the latest image references from the updated Kustomize configuration. 3. The Dependency Drift: A Tale of Two package.jsons\nI discovered a classic Node.js problem in the broadcaster service.\nThe Mistake: The package.json and package-lock.json files were out of sync. The lock file contained a different version of axios and even included winston, a package that wasn\u0026rsquo;t listed as a dependency at all. This is a recipe for \u0026ldquo;it works on my machine\u0026rdquo; bugs. The Fix: The fix was simple but crucial: I ran npm install in the service\u0026rsquo;s directory and committed the updated package.json. This ensures that both local development and the CI/CD pipeline build from the exact same dependency tree. 4. The Inefficiency: A Heavy Frontend for a Light Job\nMy frontend was over-engineered.\nThe Mistake: I was using a full Node.js Koa server to serve what was essentially a single, dynamically generated HTML file. My own Dockerfile even had a commented-out nginx implementation that I had ignored. The Fix (Next Step): The plan is to refactor this into a multi-stage Docker build. A node stage will build the static HTML file, and a final, lightweight nginx stage will serve it. This will result in a smaller, faster, and more secure container. Chapter 9: The Kustomize Conundrum and Service Connectivity Just when I thought the deployment was stable, new challenges emerged, highlighting the intricate dance between Kustomize, ArgoCD, and inter-service communication.\n1. The Stubborn ImagePullBackOff: Kustomize Overlays vs. Reality\nEven after correctly configuring GCR project IDs and ensuring my CI/CD pushed SHA-tagged images, pods were still stuck in ImagePullBackOff, trying to pull images with the staging-initial tag.\nThe Problem: My base Kustomize configuration specified newTag: staging-initial for the images. Kubernetes tried to pull these images immediately. However, my CI/CD pipeline builds images with SHA-based tags (e.g., staging-b287111) and then updates the kustomization.yaml in the overlays/staging directory with these new, correct tags. The staging-initial image simply didn\u0026rsquo;t exist in my GCR. The Docker Hub Detour (and why it was a band-aid): In an attempt to unblock, I temporarily switched the overlays/staging/kustomization.yaml to point to Docker Hub images. This was a quick fix to get any image pulled, but it wasn\u0026rsquo;t the long-term solution as my CI/CD pipeline pushes to GCR. The Strategic Merge Patch Breakthrough: The real solution came from understanding Kustomize\u0026rsquo;s patching mechanisms more deeply. Instead of relying on the images: field (which seemed to be problematic for direct overrides), I created explicit strategic merge patch files for each deployment (broadcaster, todo-backend, todo-frontend). These patches directly set the image field of the container to the full GCR image path including the SHA tag (e.g., gcr.io/dwk-gke-458706/broadcaster:staging-b287111). This forced the Kubernetes Deployment objects to update their image references. The Reversion: Once this explicit patching strategy proved successful in getting the pods to pull the correct images, I reverted these hardcoded strategic merge patches. The goal is for the CI/CD pipeline to dynamically update the images: field in overlays/staging/kustomization.yaml, and for ArgoCD to correctly apply that. This is the next phase of refinement. 2. The Broadcaster\u0026rsquo;s Identity Crisis: NATS Connectivity\nEven after the image issues were resolved, the broadcaster pod was still crashing with getaddrinfo ENOTFOUND my-nats.\nThe Problem: The broadcaster service was trying to connect to the NATS server using the service name my-nats. While my-nats exists, it was deployed in the default namespace, and the broadcaster was in the staging namespace. Kubernetes service discovery requires the fully qualified domain name (FQDN) for cross-namespace communication. The Solution: I updated the NATS_URL environment variable in the broadcaster-deployment.yaml to use the FQDN: nats://my-nats.default.svc.cluster.local:4222. This allowed the broadcaster to correctly resolve and connect to the NATS service. Staging Mode Confirmation: This also confirmed that my existing broadcaster-patch.yaml (which sets DISCORD_WEBHOOK_URL to an empty string) was correctly being applied, ensuring the broadcaster runs in a safe, log-only mode in staging. Overall Application Look Here are some screenshots of the overall application:\nConclusion: I Didn\u0026rsquo;t Just Build an App, I Built a Platform This Todo app journey was my crucible. It took me from the basics of Pods and Services to the advanced, real-world challenges of stateful sets, multi-environment deployments, and secure GitOps workflows. I didn\u0026rsquo;t just learn a list of commands; I learned how to think like a cloud-native engineer.\nI now have the skills to design, build, and manage a resilient, observable, and fully automated system on Kubernetes. This project is more than just a portfolio piece; it\u0026rsquo;s a testament to the deep, practical knowledge that can only be gained by building. And I\u0026rsquo;m ready to build what\u0026rsquo;s next.\n","permalink":"http://localhost:1313/blog/my-todo-app-journey/","summary":"\u003ch4 id=\"introduction-the-project-that-taught-me-everything\"\u003e\u003cstrong\u003eIntroduction: The Project That Taught Me Everything\u003c/strong\u003e\u003c/h4\u003e\n\u003cp\u003eIn the world of DevOps, you can read documentation for months, but nothing solidifies your skills like building something real. For me, that \u0026ldquo;something\u0026rdquo; was a seemingly simple Todo application. This project, inspired by the practical challenges presented in \u003ccode\u003edevopswithkubernetes.com\u003c/code\u003e, became my personal deep dive into Kubernetes, taking me from the humble beginnings of \u003ccode\u003ekubectl apply\u003c/code\u003e on my local machine to orchestrating a state-of-the-art, multi-environment GitOps workflow on Google Kubernetes Engine (GKE).\u003c/p\u003e","title":"My Todo App Journey An Automated Cloud-Native Platform"},{"content":"Introduction As a passionate individual eager to delve into the world of DevOps, I found myself facing a common question: \u0026ldquo;What is a good beginner project to gain practical experience?\u0026rdquo; After exploring various resources and communities, I stumbled upon an insightful blog post titled \u0026ldquo;The Best DevOps Project for a Beginner\u0026rdquo; by Logan Marchione. Inspired by his guidance, I embarked on an exciting journey to build my own static website, and I would like to share my personal experience and lessons learned along the way.\nOften it is difficult to get hands-on experience in DevOps. Doing a beginner challenge could solidfy otherwise only theoretical concepts.\nStatic site He recommended building a static site. That\u0026rsquo;s the answer.\nWhy A static site is a great beginner project because:\nIt gave me a great chance to finally purchase mapuekyle.com I touched on how websites works (e.g., domain names, DNS, web hosting, certificates) Experienced more infrastructure-as-code (IaC) with Terraform I learned configuration management with Ansible I got to check how a static site generator works. Touches on how Git works Messed with continuous integration and continuous delivery (CI/CD) with GitHub Actions How Below are the steps I took based on the outline of the steps for the challenge.\nPurchase a domain I took the liberty to browse through different sites/marketplace: Hover, Cloudflare, Namecheap, AWS, etc\u0026hellip; Given that this is a personal website, I opted for a \u0026lsquo;.com\u0026rsquo; on Namecheap Create a two Github repositories One for IaC code (Terraform and Ansible) repo-iac One for static site\u0026rsquo;s code repo-static-site Provision a virtual private server (VPS) in the cloud using Terraform So I looked up the recommended options for VPS that has Terraform support: (DigitalOcean, AWS, Linode, OVH, Oracle Cloud, Scaleway, etc\u0026hellip;) For this project I used DigitalOcean (I like it because of the straightforward pricing) This code was checked out on its respective repo Notes: Don\u0026rsquo;t hard-code your API keys anywhere in your Terraform code, more like NEVER hard-code them. Notes: There is an option for me to store them on my DigitalOcean account but they can also be stored remotely (HashiCorp offers free state storage in Terraform Cloud) Improvements for future: Use Atlantis with your GitHub account to run Terraform via pull requests to GitHub Setup DNS using Terraform After I got the IP of my VPS, I linked mapuekyle.com to \u0026lt;my vps ip\u0026gt; You can use a separate DNS provider (like Cloudflare, NS1, or DNSimple ), but your VPS provider might also offer DNS (e.g., DigitalOcean, AWS Route53, Linode, Scaleway, etc\u0026hellip;) This code was checked into Git on GitHub Configure the VPS using Ansible After the VPS is online, I installed updates, setup a user, install packages, mess with configuration files, etc\u0026hellip; I also installed a webserver Nginx. This code was checked into Git on GitHub Notes: Learned that I can get a TLS certificate for free from Let\u0026rsquo;s Encrypt and configure your webserver to redirect from port 80 to 443 Improvements for future: Instead of making one big playbook, use roles Run Ansible through Docker I thought it would be a good practice for me to run my Ansible playbook through Docker (but you can definitely run it as usual) I created a dockerfile inside my Ansible directory and installed respective dependencies for me to run the playbook. Create the static site locally on your PC I choose from an extensive list of static site generator (here) I initially used a different site that runs on react but opted for~ Hugo,(consider things like speed, available themes, the language the templates are written in, plugins, if you\u0026rsquo;re migrating from another data source, etc\u0026hellip;) I chose Hugo for its simplicity and speed. This code was checked into Git on Github Deploy the site to your VPS using Setup GitHub Actions The goal is to automate deploying the static site\u0026rsquo;s rendered code from GitHub to VPS The automation is set on each push but you can definitely add other triggers (e.g., on each commit to Git, on a schedule, on a tag, etc\u0026hellip;) Improvements for the future: Use GitHub Actions to lint your Terraform code with tflint and Ansible code with ansible-lint Bonus: Setup a free GitHub Pages domain at mapuekyle.github.io and push a dev/test version of your site to there but you can also do it on Netlify. Cost In my setup, I\u0026rsquo;m spending $84/year on my site and the surrounding infrastructure.\nProduct Cost (per year) Domain (NameCheap) $12 DNS (Cloudflare) Free VPS (DigitalOcean) $72 Conclusion In conclusion, building a static website as a beginner project proved to be an excellent choice. It laid the foundation for my DevOps aspirations and provided a solid platform for future growth. I encourage fellow beginners to embark on this journey, embrace the challenges, and experience the transformative power of hands-on learning in DevOps.\nI am looking forward to doing The Cloud Resume Challenge and navigating my way through roadmap.sh).\n-Kyle\n","permalink":"http://localhost:1313/blog/devops-journey/","summary":"\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n\u003cp\u003eAs a passionate individual eager to delve into the world of DevOps, I found myself facing a common question: \u0026ldquo;What is a good beginner project to gain practical experience?\u0026rdquo; After exploring various resources and communities, I stumbled upon an insightful blog post titled \u0026ldquo;The Best DevOps Project for a Beginner\u0026rdquo; by Logan Marchione. Inspired by his guidance, I embarked on an exciting journey to build my own static website, and I would like to share my personal experience and lessons learned along the way.\u003c/p\u003e","title":"The Story of This Very Website"},{"content":"Study material from devopswithdocker.com.\nMy DevOps with Docker Journey: A Learning Log Embarking on a journey through the world of DevOps, my focus has been on mastering Docker and its ecosystem. This blog post serves as a quick recap of the key learnings and concepts explored across various exercises and chapters in my study.\nChapter 1: Docker Fundamentals - Building Blocks of Containerization Chapter 1 laid the groundwork, focusing on the absolute essentials of Docker. This is where we learned to craft Dockerfiles – the blueprints for our containerized applications.\nDockerfile Basics: Your First Containerized \u0026ldquo;Hello World\u0026rdquo; Let\u0026rsquo;s start with a simple example from exercise1.10. This Dockerfile creates an image that simply prints \u0026ldquo;Hello from Docker\u0026rdquo;.\n# chap1/exercise1.10/Dockerfile FROM alpine CMD echo \u0026#34;Hello from Docker\u0026#34; FROM alpine: This instruction specifies the base image for our container. alpine is a lightweight Linux distribution, perfect for minimal images. CMD echo \u0026quot;Hello from Docker\u0026quot;: This defines the command that will be executed when a container is launched from this image. To build this image, navigate to the exercise1.10 directory and run:\ndocker build -t my-hello-world . Once built, you can run your first container:\ndocker run my-hello-world You should see \u0026ldquo;Hello from Docker\u0026rdquo; printed to your console!\nExecuting Scripts within Containers: The improvedcurler Example Many real-world applications involve running scripts. The improvedcurler exercise demonstrated how to include and execute a shell script inside a Docker container.\nFirst, let\u0026rsquo;s look at the script.sh file:\n# chap1/improvedcurler/script.sh #!/bin/bash echo \u0026#34;Searching..\u0026#34;; sleep 1; curl http://$1; And here\u0026rsquo;s its corresponding Dockerfile:\n# chap1/improvedcurler/Dockerfile FROM alpine COPY script.sh /script.sh RUN chmod +x /script.sh ENTRYPOINT [\u0026#34;/script.sh\u0026#34;] COPY script.sh /script.sh: This instruction copies our script.sh file from the host machine into the container\u0026rsquo;s root directory. RUN chmod +x /script.sh: We need to make the script executable within the container. ENTRYPOINT [\u0026quot;/script.sh\u0026quot;]: This sets the primary command for the container. Any arguments passed to docker run will be appended to this entrypoint. For example, docker run improved-curler example.com would execute /script.sh example.com. To build and run this example:\ndocker build -t improved-curler chap1/improvedcurler docker run improved-curler example.com This will attempt to curl example.com from within the container, showcasing how scripts can be integrated and executed.\nIntroduction to Multi-Service Applications While Chapter 1 focused on single-container applications, the Exercises1.11-1.14 directory, with its example-backend, example-frontend, and spring-example-project, hinted at the complexity of real-world applications. These exercises laid the groundwork for understanding the need to containerize multiple interconnected services, a concept we\u0026rsquo;ll dive deeper into with Docker Compose.\nChapter 2: Docker Compose - Orchestrating Multi-Container Applications Chapter 2 was a deep dive into docker-compose, the tool for defining and running multi-container Docker applications. This chapter was crucial for understanding how to manage complex service architectures efficiently.\nDefining Services with docker-compose.yml: A Simple Web Service Almost every exercise in this chapter revolved around creating and configuring docker-compose.yml files. Let\u0026rsquo;s look at a basic example from ex2.2 that defines a simple web service:\n# chap2/ex2.2/docker-compose.yml version: \u0026#39;3.8\u0026#39; services: message-server: image: devopsdockeruh/simple-web-service:alpine command: server ports: - 127.0.0.1:8080:8080 version: '3.8': Specifies the Docker Compose file format version. services: Defines the different services that make up your application. Here, we have message-server. image: The Docker image to use for this service. command: Overrides the default command specified in the image\u0026rsquo;s Dockerfile. ports: Maps a port on your host machine (127.0.0.1:8080) to a port inside the container (8080). This allows you to access the service from your host. To run this service, navigate to the ex2.2 directory and execute:\ndocker compose up Service Intercommunication, Networking, and Volumes: A Full-Stack Example Real-world applications often consist of multiple interconnected services, such as a frontend, backend, and database. ex2.7 provides a great example of how Docker Compose facilitates this intercommunication:\n# chap2/ex2.7/docker-compose.yml version: \u0026#39;3.8\u0026#39; services: frontend: image: frontend:latest ports: - 127.0.0.1:5000:5000 backend: image: backend:latest ports: - 127.0.0.1:8080:8080 environment: - REDIS_HOST=redis # Use the Redis service name - POSTGRES_HOST=db depends_on: - redis # Ensure Redis starts before the backend - db redis: image: redis:8.0-M02-alpine restart: unless-stopped db: image: postgres:13.2-alpine restart: unless-stopped environment: POSTGRES_PASSWORD: postgres container_name: db_postgres volumes: - ./database:/var/lib/postgresql/data Key concepts demonstrated here:\nService Discovery: Services within the same Docker Compose network can communicate with each other using their service names (e.g., backend can reach redis and db by their names). environment: Sets environment variables within the container, crucial for configuring applications (e.g., database connection strings). depends_on: Ensures that services start in a specific order. Here, backend will only start after redis and db are running. volumes: Mounts a host path (./database) into the container (/var/lib/postgresql/data). This is essential for persistent data storage, ensuring your database data isn\u0026rsquo;t lost when containers are removed. restart: unless-stopped: Configures the container to restart automatically unless explicitly stopped. To bring up this multi-service application:\ndocker compose up Scaling and Load Balancing The scaling-exercise and whoamiscale directories were key to understanding how to scale services horizontally and distribute traffic among them, a core DevOps practice. While docker-compose itself has basic scaling capabilities (docker compose up --scale service_name=N), more advanced load balancing and scaling often involve external tools or orchestrators like Kubernetes, which build upon these fundamental concepts.\nThis chapter solidified the understanding of how to define, link, and manage complex multi-container applications, laying the groundwork for robust DevOps practices.\nChapter 3: Advanced Docker \u0026amp; Deployment Patterns Chapter 3 moved beyond basic orchestration into more advanced topics, touching upon build processes, CI/CD considerations, and more complex deployment scenarios.\nAutomated Builds: The builder.sh Script Automating the Docker image build process is a crucial step towards Continuous Integration (CI). The builder.sh script in ex3.3 provides a great example of how to automate building and pushing Docker images to a registry like Docker Hub.\n# chap3/ex3.3/builder.sh #!/bin/bash # Check if the correct number of arguments is passed if [ \u0026#34;$#\u0026#34; -ne 2 ]; then echo \u0026#34;Usage: $0 \u0026lt;github-repo\u0026gt; \u0026lt;dockerhub-repo\u0026gt;\u0026#34; echo \u0026#34;Example: $0 mluukkai/express_app mluukkai/testing\u0026#34; exit 1 fi # Parse arguments GITHUB_REPO=$1 DOCKERHUB_REPO=$2 # Extract the repo name from the GitHub URL REPO_NAME=$(basename \u0026#34;$GITHUB_REPO\u0026#34;) # Step 1: Clone the GitHub repository echo \u0026#34;Cloning repository https://github.com/$GITHUB_REPO...\u0026#34; git clone \u0026#34;https://github.com/$GITHUB_REPO.git\u0026#34; || { echo \u0026#34;Failed to clone the repository\u0026#34;; exit 1; } # Step 2: Change into the cloned repository directory cd \u0026#34;$REPO_NAME\u0026#34; || { echo \u0026#34;Failed to access the repository directory\u0026#34;; exit 1; } # Step 3: Build the Docker image echo \u0026#34;Building Docker image $DOCKERHUB_REPO...\u0026#34; docker build -t \u0026#34;$DOCKERHUB_REPO\u0026#34; . || { echo \u0026#34;Failed to build the Docker image\u0026#34;; exit 1; } # Step 4: Push the Docker image to Docker Hub echo \u0026#34;Logging into Docker Hub...\u0026#34; docker login || { echo \u0026#34;Docker login failed\u0026#34;; exit 1; } echo \u0026#34;Pushing Docker image to Docker Hub...\u0026#34; docker push \u0026#34;$DOCKERHUB_REPO\u0026#34; || { echo \u0026#34;Failed to push the Docker image\u0026#34;; exit 1; } # Step 5: Cleanup (optional) cd .. echo \u0026#34;Cleaning up...\u0026#34; rm -rf \u0026#34;$REPO_NAME\u0026#34; echo \u0026#34;Done! The Docker image is available at Docker Hub: $DOCKERHUB_REPO\u0026#34; This script automates the entire process: cloning a Git repository, building a Docker image from its contents, logging into Docker Hub, pushing the image, and finally cleaning up. This is a fundamental pattern in CI/CD pipelines.\nScripted Container Execution: Running Tasks within Docker ex3.4 demonstrates how to create a Docker image that executes a specific script upon startup. This is useful for running automated tasks, cron jobs, or one-off operations within a controlled environment.\nHere\u0026rsquo;s the Dockerfile from ex3.4:\n# chap3/ex3.4/Dockerfile FROM docker:latest RUN apk add --no-cache bash WORKDIR /app COPY script.sh /app/script.sh RUN chmod +x /app/script.sh ENTRYPOINT [\u0026#34;/app/script.sh\u0026#34;] And the script.sh it uses:\n# chap3/ex3.4/script.sh #!/bin/bash # Check if the correct number of arguments is passed if [ \u0026#34;$#\u0026#34; -ne 2 ]; then echo \u0026#34;Usage: $0 \u0026lt;github-repo\u0026gt; \u0026lt;dockerhub-repo\u0026gt;\u0026#34; echo \u0026#34;Example: $0 mluukkai/express_app mluukkai/testing\u0026#34; exit 1 fi # Parse arguments GITHUB_REPO=$1 DOCKERHUB_REPO=$2 # Extract the repo name from the GitHub URL REPO_NAME=$(basename \u0026#34;$GITHUB_REPO\u0026#34;) # Step 1: Clone the GitHub repository echo \u0026#34;Cloning repository https://github.com/$GITHUB_REPO...\u0026#34; git clone \u0026#34;https://github.com/$GITHUB_REPO.git\u0026#34; || { echo \u0026#34;Failed to clone the repository\u0026#34;; exit 1; } # Step 2: Change into the cloned repository directory cd \u0026#34;$REPO_NAME\u0026#34; || { echo \u0026#34;Failed to access the repository directory\u0026#34;; exit 1; } # Step 3: Build the Docker image echo \u0026#34;Building Docker image $DOCKERHUB_REPO...\u0026#34; docker build -t \u0026#34;$DOCKERHUB_REPO\u0026#34; . || { echo \u0026#34;Failed to build the Docker image\u0026#34;; exit 1; } # Step 4: Push the Docker image to Docker Hub echo \u0026#34;Logging into Docker Hub...\u0026#34; docker login -u \u0026#34;$DOCKER_USER\u0026#34; -p \u0026#34;$DOCKER_PWD\u0026#34; || { echo \u0026#34;Docker login failed\u0026#34;; exit 1; } echo \u0026#34;Pushing Docker image to Docker Hub...\u0026#34; docker push \u0026#34;$DOCKERHUB_REPO\u0026#34; || { echo \u0026#34;Failed to push the Docker image\u0026#34;; exit 1; } # Step 5: Cleanup (optional) cd .. echo \u0026#34;Cleaning up...\u0026#34; rm -rf \u0026#34;$REPO_NAME\u0026#34; echo \u0026#34;Done! The Docker image is available at Docker Hub: $DOCKERHUB_REPO\u0026#34; This setup allows you to encapsulate a specific task within a Docker image, making it portable and reproducible. You can build this image and run it, passing arguments directly to the script.sh.\nComplex Multi-Service Deployments Exercises like ex3.5 through ex3.8-3.9 continued to build on multi-service applications (example-backend, example-frontend) integrated with docker-compose.yml and nginx.conf. These likely involved more sophisticated configurations for production-like environments, including environment variables, health checks, and advanced networking. These examples showcase how to combine the concepts from previous chapters to create robust and scalable multi-service architectures.\nThis journey has provided a solid foundation in containerization with Docker, from single-service deployments to complex, scalable, multi-container applications, laying the groundwork for robust DevOps practices.\n","permalink":"http://localhost:1313/blog/devops-with-docker/","summary":"\u003cp\u003e\u003cem\u003eStudy material from \u003ca href=\"https://devopswithdocker.com/\"\u003edevopswithdocker.com\u003c/a\u003e.\u003c/em\u003e\u003c/p\u003e\n\u003ch1 id=\"my-devops-with-docker-journey-a-learning-log\"\u003eMy DevOps with Docker Journey: A Learning Log\u003c/h1\u003e\n\u003cp\u003eEmbarking on a journey through the world of DevOps, my focus has been on mastering Docker and its ecosystem. This blog post serves as a quick recap of the key learnings and concepts explored across various exercises and chapters in my study.\u003c/p\u003e\n\u003ch2 id=\"chapter-1-docker-fundamentals---building-blocks-of-containerization\"\u003eChapter 1: Docker Fundamentals - Building Blocks of Containerization\u003c/h2\u003e\n\u003cp\u003eChapter 1 laid the groundwork, focusing on the absolute essentials of Docker. This is where we learned to craft \u003ccode\u003eDockerfile\u003c/code\u003es – the blueprints for our containerized applications.\u003c/p\u003e","title":"My DevOps with Docker Journey: A Learning Log"},{"content":"","permalink":"http://localhost:1313/404.html","summary":"","title":"404"}]